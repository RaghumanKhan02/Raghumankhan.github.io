{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80026fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "\n",
      "Training with <keras.optimizers.adam.Adam object at 0x00000261B2189360> optimizer...\n",
      "Epoch 1/10\n",
      "718/718 [==============================] - 594s 824ms/step - loss: 0.6447 - accuracy: 0.6024 - val_loss: 0.5435 - val_accuracy: 0.7365\n",
      "Epoch 2/10\n",
      "718/718 [==============================] - 612s 851ms/step - loss: 0.4881 - accuracy: 0.7639 - val_loss: 0.4415 - val_accuracy: 0.7795\n",
      "Epoch 3/10\n",
      "718/718 [==============================] - 613s 853ms/step - loss: 0.3873 - accuracy: 0.8287 - val_loss: 0.3597 - val_accuracy: 0.8360\n",
      "Epoch 4/10\n",
      "718/718 [==============================] - 561s 780ms/step - loss: 0.3056 - accuracy: 0.8710 - val_loss: 0.3441 - val_accuracy: 0.8455\n",
      "Epoch 5/10\n",
      "718/718 [==============================] - 563s 783ms/step - loss: 0.2523 - accuracy: 0.8946 - val_loss: 0.2869 - val_accuracy: 0.8745\n",
      "Epoch 6/10\n",
      "718/718 [==============================] - 572s 796ms/step - loss: 0.2014 - accuracy: 0.9171 - val_loss: 0.2693 - val_accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "718/718 [==============================] - 561s 781ms/step - loss: 0.1613 - accuracy: 0.9352 - val_loss: 0.2892 - val_accuracy: 0.8845\n",
      "Epoch 8/10\n",
      "718/718 [==============================] - 561s 780ms/step - loss: 0.1306 - accuracy: 0.9478 - val_loss: 0.3108 - val_accuracy: 0.8925\n",
      "Epoch 9/10\n",
      "718/718 [==============================] - 572s 795ms/step - loss: 0.0976 - accuracy: 0.9618 - val_loss: 0.3471 - val_accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "718/718 [==============================] - 561s 781ms/step - loss: 0.0857 - accuracy: 0.9655 - val_loss: 0.3617 - val_accuracy: 0.8995\n",
      "\n",
      "Training with <keras.optimizers.rmsprop.RMSprop object at 0x00000261BE201000> optimizer...\n",
      "Epoch 1/10\n",
      "718/718 [==============================] - 578s 803ms/step - loss: 0.6258 - accuracy: 0.6377 - val_loss: 0.5222 - val_accuracy: 0.7420\n",
      "Epoch 2/10\n",
      "718/718 [==============================] - 562s 782ms/step - loss: 0.4666 - accuracy: 0.7808 - val_loss: 0.3812 - val_accuracy: 0.8210\n",
      "Epoch 3/10\n",
      "718/718 [==============================] - 559s 778ms/step - loss: 0.3616 - accuracy: 0.8407 - val_loss: 0.3147 - val_accuracy: 0.8655\n",
      "Epoch 4/10\n",
      "718/718 [==============================] - 556s 773ms/step - loss: 0.2909 - accuracy: 0.8764 - val_loss: 0.2820 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "718/718 [==============================] - 557s 776ms/step - loss: 0.2417 - accuracy: 0.9011 - val_loss: 0.4224 - val_accuracy: 0.8475\n",
      "Epoch 6/10\n",
      "718/718 [==============================] - 557s 775ms/step - loss: 0.1995 - accuracy: 0.9188 - val_loss: 0.2758 - val_accuracy: 0.8845\n",
      "Epoch 7/10\n",
      "718/718 [==============================] - 557s 774ms/step - loss: 0.1697 - accuracy: 0.9327 - val_loss: 0.2768 - val_accuracy: 0.8820\n",
      "Epoch 8/10\n",
      "718/718 [==============================] - 554s 771ms/step - loss: 0.1432 - accuracy: 0.9455 - val_loss: 0.2881 - val_accuracy: 0.8930\n",
      "Epoch 9/10\n",
      "718/718 [==============================] - 560s 778ms/step - loss: 0.1197 - accuracy: 0.9565 - val_loss: 0.3742 - val_accuracy: 0.8830\n",
      "Epoch 10/10\n",
      "718/718 [==============================] - 557s 775ms/step - loss: 0.1085 - accuracy: 0.9594 - val_loss: 0.3730 - val_accuracy: 0.9045\n",
      "\n",
      "Training with <keras.optimizers.sgd.SGD object at 0x00000261BE201AB0> optimizer...\n",
      "Epoch 1/10\n",
      "718/718 [==============================] - 542s 753ms/step - loss: 0.6878 - accuracy: 0.5495 - val_loss: 0.6810 - val_accuracy: 0.5360\n",
      "Epoch 2/10\n",
      "718/718 [==============================] - 544s 756ms/step - loss: 0.6711 - accuracy: 0.5880 - val_loss: 0.6515 - val_accuracy: 0.6300\n",
      "Epoch 3/10\n",
      "718/718 [==============================] - 542s 754ms/step - loss: 0.6567 - accuracy: 0.6073 - val_loss: 0.6463 - val_accuracy: 0.6195\n",
      "Epoch 4/10\n",
      "718/718 [==============================] - 542s 755ms/step - loss: 0.6397 - accuracy: 0.6339 - val_loss: 0.6715 - val_accuracy: 0.5710\n",
      "Epoch 5/10\n",
      "718/718 [==============================] - 562s 782ms/step - loss: 0.6201 - accuracy: 0.6543 - val_loss: 0.6198 - val_accuracy: 0.6350\n",
      "Epoch 6/10\n",
      "718/718 [==============================] - 545s 758ms/step - loss: 0.5900 - accuracy: 0.6885 - val_loss: 0.5706 - val_accuracy: 0.7075\n",
      "Epoch 7/10\n",
      "718/718 [==============================] - 544s 757ms/step - loss: 0.5519 - accuracy: 0.7155 - val_loss: 0.5154 - val_accuracy: 0.7485\n",
      "Epoch 8/10\n",
      "718/718 [==============================] - 547s 760ms/step - loss: 0.5234 - accuracy: 0.7379 - val_loss: 0.4921 - val_accuracy: 0.7635\n",
      "Epoch 9/10\n",
      "718/718 [==============================] - 544s 756ms/step - loss: 0.5001 - accuracy: 0.7560 - val_loss: 0.4841 - val_accuracy: 0.7720\n",
      "Epoch 10/10\n",
      "718/718 [==============================] - 546s 759ms/step - loss: 0.4772 - accuracy: 0.7710 - val_loss: 0.5017 - val_accuracy: 0.7525\n",
      "\n",
      "Optimizer: <keras.optimizers.adam.Adam object at 0x00000261B2189360>\n",
      "Training Accuracy: [0.6024347543716431, 0.7639130353927612, 0.8286956548690796, 0.8710435032844543, 0.894565224647522, 0.9171304106712341, 0.9351739287376404, 0.947826087474823, 0.9617826342582703, 0.9655217528343201]\n",
      "Validation Accuracy: [0.7365000247955322, 0.7795000076293945, 0.8360000252723694, 0.8454999923706055, 0.8744999766349792, 0.887499988079071, 0.8845000267028809, 0.8924999833106995, 0.8855000138282776, 0.8995000123977661]\n",
      "Training Loss: [0.6446820497512817, 0.48809048533439636, 0.3873101770877838, 0.3056224584579468, 0.25234395265579224, 0.20142671465873718, 0.161296084523201, 0.13063399493694305, 0.09759686142206192, 0.08573275059461594]\n",
      "Validation Loss: [0.5435079336166382, 0.441505491733551, 0.35965126752853394, 0.34412965178489685, 0.2869051396846771, 0.26933905482292175, 0.28923875093460083, 0.31080561876296997, 0.34705784916877747, 0.3617205023765564]\n",
      "\n",
      "Optimizer: <keras.optimizers.rmsprop.RMSprop object at 0x00000261BE201000>\n",
      "Training Accuracy: [0.6376521587371826, 0.7808260917663574, 0.8406521677970886, 0.8763912916183472, 0.9010869860649109, 0.9187825918197632, 0.9326956272125244, 0.9454782605171204, 0.95652174949646, 0.9594348073005676]\n",
      "Validation Accuracy: [0.7419999837875366, 0.8209999799728394, 0.8654999732971191, 0.875, 0.8475000262260437, 0.8845000267028809, 0.8820000290870667, 0.8930000066757202, 0.8830000162124634, 0.9045000076293945]\n",
      "Training Loss: [0.6258078813552856, 0.46661558747291565, 0.3616315424442291, 0.2909170687198639, 0.2417142540216446, 0.19948804378509521, 0.1696738749742508, 0.14317713677883148, 0.11969951540231705, 0.1085091084241867]\n",
      "Validation Loss: [0.5221992135047913, 0.38118812441825867, 0.31470221281051636, 0.28199607133865356, 0.42237240076065063, 0.2757914960384369, 0.27682310342788696, 0.2880752980709076, 0.37415140867233276, 0.3729601204395294]\n",
      "\n",
      "Optimizer: <keras.optimizers.sgd.SGD object at 0x00000261BE201AB0>\n",
      "Training Accuracy: [0.5495217442512512, 0.5879565477371216, 0.6072608828544617, 0.6338695883750916, 0.6543043255805969, 0.6884782314300537, 0.715478241443634, 0.7378695607185364, 0.7560434937477112, 0.7710000276565552]\n",
      "Validation Accuracy: [0.5360000133514404, 0.6299999952316284, 0.6194999814033508, 0.5709999799728394, 0.6349999904632568, 0.7074999809265137, 0.7484999895095825, 0.7634999752044678, 0.7720000147819519, 0.7524999976158142]\n",
      "Training Loss: [0.6878103613853455, 0.67112797498703, 0.6566852927207947, 0.6396900415420532, 0.6200894713401794, 0.589989960193634, 0.5518726706504822, 0.5234362483024597, 0.5001010298728943, 0.4772043228149414]\n",
      "Validation Loss: [0.6810487508773804, 0.6515052914619446, 0.6463496088981628, 0.6714696288108826, 0.6197535991668701, 0.5705950856208801, 0.5153676271438599, 0.492095023393631, 0.4840908348560333, 0.5016998648643494]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Define paths to your train and validation folders\n",
    "train_data_dir = \"C:/Users/91790/Downloads/Dogs and cats/train\"\n",
    "valid_data_dir = \"C:/Users/91790/Downloads/Dogs and cats/valid\"\n",
    "\n",
    "# Define constants\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 150, 150\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Shuffle the training data\n",
    "train_files = os.listdir(train_data_dir)\n",
    "random.shuffle(train_files)\n",
    "\n",
    "# Split into training and validation sets\n",
    "num_train_samples = int(0.9 * len(train_files))\n",
    "train_filenames = train_files[:num_train_samples]\n",
    "valid_filenames = train_files[num_train_samples:]\n",
    "\n",
    "# Define data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Define a function to create and train the model with different optimizers\n",
    "def train_model(optimizer):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "# Train the model with different optimizers\n",
    "optimizers = [Adam(), RMSprop(), SGD()]\n",
    "histories = []\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    print(f\"\\nTraining with {str(optimizer)} optimizer...\")\n",
    "    history = train_model(optimizer)\n",
    "    histories.append(history)\n",
    "\n",
    "# Print loss, accuracy, validation loss, and validation accuracy for each optimizer\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    print(f\"\\nOptimizer: {str(optimizer)}\")\n",
    "    print(\"Training Accuracy:\", histories[i].history['accuracy'])\n",
    "    print(\"Validation Accuracy:\", histories[i].history['val_accuracy'])\n",
    "    print(\"Training Loss:\", histories[i].history['loss'])\n",
    "    print(\"Validation Loss:\", histories[i].history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Best Training Accuracy, Validation accuracy And Training Loss, Validation Loss\n",
    "\n",
    "#Adam Optimizer:\n",
    "\n",
    "Training Accuracy: ~96.55%\n",
    "Validation Accuracy: ~89.95%\n",
    "Training Loss: ~0.0857\n",
    "Validation Loss: ~0.3617\n",
    "    \n",
    "#RMSprop Optimizer:\n",
    "\n",
    "Training Accuracy: ~95.94%\n",
    "Validation Accuracy: ~90.45%\n",
    "Training Loss: ~0.1085\n",
    "Validation Loss: ~0.3730\n",
    "    \n",
    "#SGD Optimizer:\n",
    "\n",
    "Training Accuracy: ~77.10%\n",
    "Validation Accuracy: ~75.25%\n",
    "Training Loss: ~0.4772\n",
    "Validation Loss: ~0.5017\n",
    "\n",
    "    \n",
    "Project Report: Building a Dogs and Cats Image Classifier\n",
    "\n",
    "1. Introduction:\n",
    "\n",
    " *The objective of this project was to build an image classifier capable of distinguishing between images of dogs and cats.\n",
    " *Convolutional Neural Networks (CNNs) were employed for this task due to their effectiveness in image classification tasks.\n",
    " *Three different optimizers (Adam, RMSprop, and SGD) were evaluated to determine their impact on model performance.\n",
    "\n",
    "2. Dataset Description:\n",
    "\n",
    " *The Dogs and Cats dataset consists of images of dogs and cats.\n",
    " *The dataset was divided into training and validation sets, with 23,000 images for training and 2,000 images for validation.\n",
    "    \n",
    "3. Methodology:\n",
    "\n",
    "#Data Preprocessing:\n",
    " *Images were resized to 150x150 pixels and normalized to the range [0, 1].\n",
    " *Data augmentation techniques such as rotation, horizontal flip, and zoom were not explicitly applied but could be considered for further experimentation.\n",
    "\n",
    "#Model Architecture:\n",
    " *A sequential CNN model was constructed consisting of convolutional layers, max-pooling layers, flattening, dense layers, and dropout for regularization.\n",
    " *The architecture aimed to learn hierarchical features from the input images, followed by classification using fully connected layers.\n",
    "\n",
    "#Training Procedure:\n",
    " *The model was trained using the three specified optimizers (Adam, RMSprop, and SGD).\n",
    " *Each optimizer was trained for 10 epochs with a batch size of 32.\n",
    " *Training and validation accuracy and loss were monitored to assess model performance.\n",
    "    \n",
    "4. Results and Discussion:\n",
    "\n",
    "#Adam Optimizer:\n",
    " *Achieved a training accuracy of ~96.55% and validation accuracy of ~89.95%.\n",
    " *Training and validation loss converged steadily, indicating effective optimization.\n",
    " *No significant signs of overfitting or underfitting were observed.\n",
    "    \n",
    "#RMSprop Optimizer:\n",
    " *Attained a training accuracy of ~95.94% and validation accuracy of ~90.45%.\n",
    " *Similar performance to the Adam optimizer, with convergence in training and validation loss.\n",
    " *No clear signs of overfitting or underfitting were evident.\n",
    "    \n",
    "#SGD Optimizer:\n",
    " *Demonstrated signs of underfitting with a training accuracy of ~77.10% and validation accuracy of ~75.25%.\n",
    " *Both training and validation loss remained relatively high, indicating insufficient model capacity or optimization.\n",
    "\n",
    "5. Conclusion:\n",
    "\n",
    " *The project successfully developed a dogs and cats image classifier using CNNs.\n",
    " *Both Adam and RMSprop optimizers yielded satisfactory results with high accuracy and well-converged loss.\n",
    " *The SGD optimizer showed signs of underfitting, suggesting a need for further model refinement or optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f3531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
